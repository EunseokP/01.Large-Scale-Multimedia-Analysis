{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import sys\n",
    "import threading\n",
    "import cv2\n",
    "import numpy as np\n",
    "import yaml\n",
    "import pickle\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.mobilenet_v2(pretrained=True)\n",
    "model.classifier = nn.Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(model, image_pil):\n",
    "    scaler = transforms.Resize((224, 224))\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    to_tensor = transforms.ToTensor()\n",
    "    t_img = Variable(normalize(to_tensor(scaler(image_pil))).unsqueeze(0))\n",
    "    foo = model(t_img)\n",
    "    return foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_features_from_video(downsampled_video_filename, video_name, keyframe_interval):\n",
    "    \"Receives filename of downsampled video and of output path for features. Extracts features in the given keyframe_interval. Saves features in pickled file.\"\n",
    "\n",
    "    images = get_keyframes(downsampled_video_filename, keyframe_interval)\n",
    "    data = []\n",
    "    counter = 0\n",
    "    for image in images:\n",
    "        image_cv = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "        image_pil = Image.fromarray(image_cv)\n",
    "#        cv2.imwrite('frame.jpg', image)\n",
    "        features = get_features(model, image_pil)\n",
    "        data.append(features)\n",
    "    print(downsampled_video_filename)\n",
    "    try:\n",
    "        data = np.array(data)\n",
    "    except:\n",
    "        #continue\n",
    "        pass\n",
    "        \n",
    "#    if data is not []:\n",
    "    pickle.dump(data, open(str('cnn/'+video_name+'.pkl'), 'wb'))\n",
    "    #np.savez('cnn/'+video_name+'.npz',data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keyframes(downsampled_video_filename, keyframe_interval):\n",
    "    \"Generator function which returns the next keyframe.\"\n",
    "\n",
    "    # Create video capture object\n",
    "    video_cap = cv2.VideoCapture(downsampled_video_filename)\n",
    "    frame = 0\n",
    "    while True:\n",
    "        frame += 1\n",
    "        ret, img = video_cap.read()\n",
    "        if ret is False:\n",
    "            break\n",
    "        if frame % keyframe_interval == 0:\n",
    "            yield img\n",
    "    video_cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python surf_feat_extraction.py -i list/all.video config.yaml\n",
    "all_video_names = 'list/all.video'#sys.argv[1]\n",
    "config_file = 'config.yaml'#sys.argv[2]\n",
    "my_params = yaml.load(open(config_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get parameters from config file\n",
    "keyframe_interval = my_params.get('keyframe_interval')\n",
    "hessian_threshold = my_params.get('hessian_threshold')\n",
    "# surf_features_folderpath = my_params.get('surf_features')\n",
    "downsampled_videos = my_params.get('downsampled_videos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fread = open(all_video_names, \"r\")\n",
    "for line in fread.readlines():\n",
    "    video_name = line.replace('\\n', '')\n",
    "    downsampled_video_filename = os.path.join(downsampled_videos, video_name + '.ds.mp4')\n",
    "#     surf_feat_video_filename = os.path.join(surf_features_folderpath, video_name + '.surf')\n",
    "\n",
    "    if not os.path.isfile(downsampled_video_filename):\n",
    "        continue\n",
    "\n",
    "    # Get SURF features for one video\n",
    "    get_cnn_features_from_video(downsampled_video_filename,\n",
    "                                 video_name, keyframe_interval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = get_keyframes('./downsampled_videos/HVC1012.ds.mp4', keyframe_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in foo:\n",
    "    print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
