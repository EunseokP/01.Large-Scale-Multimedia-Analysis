{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import scipy.sparse \n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics.pairwise import chi2_kernel\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = './hw1_git/11775-hws/videos/*.mp4'\n",
    "path = './hw1_git/11775-hws/asrs/*.txt'\n",
    "\n",
    "filelist = []\n",
    "\n",
    "for file in glob.glob(path):\n",
    "    filelist.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_list_data(list):\n",
    "    result= ''\n",
    "    for element in list:\n",
    "        result += str(element)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th txt file reading...\n",
      "1000th txt file reading...\n",
      "2000th txt file reading...\n"
     ]
    }
   ],
   "source": [
    "text = []\n",
    "for i in range(len(filelist)):\n",
    "# for i in range(10):\n",
    "    with open (filelist[i], \"r\") as myfile:\n",
    "        data=myfile.readlines()\n",
    "        data=concatenate_list_data(data)\n",
    "    text.append(data)\n",
    "    if i % 1000 == 0:\n",
    "        print('{}th txt file reading...'.format(i))\n",
    "    else: pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorizer TDIF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3522</th>\n",
       "      <th>3523</th>\n",
       "      <th>3524</th>\n",
       "      <th>3525</th>\n",
       "      <th>3526</th>\n",
       "      <th>3527</th>\n",
       "      <th>3528</th>\n",
       "      <th>3529</th>\n",
       "      <th>3530</th>\n",
       "      <th>3531</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 3532 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3     4     5     6     7     8     9     ...  3522  \\\n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "\n",
       "   3523  3524  3525  3526  3527  3528  3529  3530  3531  \n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[3 rows x 3532 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##TF-IDF Vectorization\n",
    "vectorize = TfidfVectorizer(stop_words=\"english\",min_df=2,sublinear_tf=True)#, norm='l1')    # tf값에 1+log(tf)를 적용하여 tf값이 무한정 커지는 것을 막음\n",
    "norm_bow = vectorize.fit_transform(text).toarray()\n",
    "norm_data = pd.DataFrame(norm_bow)\n",
    "norm_data.head(3)\n",
    "# bow = vectorize.fit_transform(text)#.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>6976</th>\n",
       "      <th>6977</th>\n",
       "      <th>6978</th>\n",
       "      <th>6979</th>\n",
       "      <th>6980</th>\n",
       "      <th>6981</th>\n",
       "      <th>6982</th>\n",
       "      <th>6983</th>\n",
       "      <th>6984</th>\n",
       "      <th>6985</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 6986 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3     4     5     6     7     8     9     ...  6976  \\\n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "\n",
       "   6977  6978  6979  6980  6981  6982  6983  6984  6985  \n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[3 rows x 6986 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer(stop_words=\"english\")\n",
    "# vect = CountVectorizer()\n",
    "bow = vect.fit_transform(text).toarray()\n",
    "norm_bow = normalize(bow, norm = 'l1', axis=1)\n",
    "norm_data = pd.DataFrame(norm_bow)\n",
    "norm_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ASRS Modeling..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making Video name\n",
    "video_name_ind = []\n",
    "for i in range(len(filelist)):\n",
    "    match_front = re.search('asrs/', filelist[i])\n",
    "    match_end = re.search('.txt', filelist[i])\n",
    "    video_name_ind.append(filelist[i][match_front.end():match_end.start()])\n",
    "    video_name = pd.DataFrame({'video': video_name_ind})\n",
    "#     print(i, filelist[i][match_front.end():match_end.start()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making features columns\n",
    "k = norm_data.shape[1]\n",
    "column_name = ['video']\n",
    "for i in range(k):\n",
    "    column_name.append('feature_{}'.format(i))\n",
    "\n",
    "total_data = pd.concat([video_name, norm_data], axis = 1)\n",
    "total_data.columns = column_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_6976</th>\n",
       "      <th>feature_6977</th>\n",
       "      <th>feature_6978</th>\n",
       "      <th>feature_6979</th>\n",
       "      <th>feature_6980</th>\n",
       "      <th>feature_6981</th>\n",
       "      <th>feature_6982</th>\n",
       "      <th>feature_6983</th>\n",
       "      <th>feature_6984</th>\n",
       "      <th>feature_6985</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HVC3995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HVC3694</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HVC3332</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 6987 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     video  feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0  HVC3995        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "1  HVC3694        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "2  HVC3332        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "   feature_6  feature_7  feature_8  ...  feature_6976  feature_6977  \\\n",
       "0        0.0        0.0        0.0  ...           0.0           0.0   \n",
       "1        0.0        0.0        0.0  ...           0.0           0.0   \n",
       "2        0.0        0.0        0.0  ...           0.0           0.0   \n",
       "\n",
       "   feature_6978  feature_6979  feature_6980  feature_6981  feature_6982  \\\n",
       "0           0.0           0.0           0.0           0.0           0.0   \n",
       "1           0.0           0.0           0.0           0.0           0.0   \n",
       "2           0.0           0.0           0.0           0.0           0.0   \n",
       "\n",
       "   feature_6983  feature_6984  feature_6985  \n",
       "0           0.0           0.0           0.0  \n",
       "1           0.0           0.0           0.0  \n",
       "2           0.0           0.0           0.0  \n",
       "\n",
       "[3 rows x 6987 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ind = pd.read_csv('./hw1_git/11775-hws/hw1_code/list/train', sep = ' ', header = None)\n",
    "valid_ind = pd.read_csv('./hw1_git/11775-hws/hw1_code/list/val', sep = ' ', header = None)\n",
    "test_ind = pd.read_csv('./hw1_git/11775-hws/hw1_code/list/test.video', sep = ' ', header = None)\n",
    "\n",
    "train_ind['Data'] = 'TRAIN'\n",
    "valid_ind['Data'] = 'VALID'\n",
    "test_ind[1] = 'UNK'\n",
    "test_ind['Data'] = 'TEST'\n",
    "\n",
    "train_ind.columns = ['video','target','Data']\n",
    "valid_ind.columns = ['video','target','Data']\n",
    "test_ind.columns = ['video','target','Data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "data_lable = pd.concat([train_ind, valid_ind, test_ind], axis = 0).reset_index().drop('index', axis = 1)\n",
    "# data_lable['target_p001'] = \n",
    "data_lable['target_p001'] = data_lable['target']\n",
    "data_lable['target_p002'] = data_lable['target']\n",
    "data_lable['target_p003'] = data_lable['target']\n",
    "data_lable['target_p001_10'] = 1\n",
    "data_lable['target_p002_10'] = 1\n",
    "data_lable['target_p003_10'] = 1\n",
    "\n",
    "data_lable['target_p001'][data_lable['target'] != 'P001'] = 'Other'\n",
    "data_lable['target_p002'][data_lable['target'] != 'P002'] = 'Other'\n",
    "data_lable['target_p003'][data_lable['target'] != 'P003'] = 'Other'\n",
    "data_lable['target_p001_10'][data_lable['target'] != 'P001'] = 0\n",
    "data_lable['target_p002_10'][data_lable['target'] != 'P002'] = 0\n",
    "data_lable['target_p003_10'][data_lable['target'] != 'P003'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_mart = total_data.merge(data_lable, how = 'right', on = 'video')\n",
    "total_mart = total_mart.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mart = total_mart[total_mart['Data'] == 'TRAIN']\n",
    "valid_mart = total_mart[total_mart['Data'] == 'VALID']\n",
    "test_mart  = total_mart[total_mart['Data'] == 'TEST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((836, 6995), (400, 6995), (1699, 6995))\n"
     ]
    }
   ],
   "source": [
    "print(train_mart.shape, valid_mart.shape, test_mart.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_6984</th>\n",
       "      <th>feature_6985</th>\n",
       "      <th>target</th>\n",
       "      <th>Data</th>\n",
       "      <th>target_p001</th>\n",
       "      <th>target_p002</th>\n",
       "      <th>target_p003</th>\n",
       "      <th>target_p001_10</th>\n",
       "      <th>target_p002_10</th>\n",
       "      <th>target_p003_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HVC3694</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HVC711</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>P002</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>Other</td>\n",
       "      <td>P002</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>HVC3481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 6995 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      video  feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "1   HVC3694        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "3    HVC711        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "19  HVC3481        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "    feature_6  feature_7  feature_8  ...  feature_6984  feature_6985  target  \\\n",
       "1         0.0        0.0        0.0  ...           0.0           0.0       0   \n",
       "3         0.0        0.0        0.0  ...           0.0           0.0    P002   \n",
       "19        0.0        0.0        0.0  ...           0.0           0.0       0   \n",
       "\n",
       "     Data  target_p001  target_p002  target_p003  target_p001_10  \\\n",
       "1   TRAIN        Other        Other        Other               0   \n",
       "3   TRAIN        Other         P002        Other               0   \n",
       "19  TRAIN        Other        Other        Other               0   \n",
       "\n",
       "    target_p002_10  target_p003_10  \n",
       "1                0               0  \n",
       "3                1               0  \n",
       "19               0               0  \n",
       "\n",
       "[3 rows x 6995 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mart.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeling_ap_SVM(k, train_data, valid_data, target = 'target_p001_10'):\n",
    "    start_time = time.time()\n",
    "    k = k\n",
    "    train_mart = train_data\n",
    "    valid_mart = valid_data\n",
    "    target = target\n",
    "    \n",
    "    X_train = train_mart.iloc[:,1:k+1]\n",
    "    y_train = train_mart[target]\n",
    "    X_valid = valid_mart.iloc[:,1:k+1]\n",
    "    y_valid = valid_mart[target]\n",
    "    \n",
    "    model = SVC(kernel=chi2_kernel, probability=True)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_preds = model.predict(X_valid)\n",
    "    y_probs = model.predict_proba(X_valid)\n",
    "    results = average_precision_score(y_true=y_valid.values, y_score=y_probs[:,1])\n",
    "    print(\"===== The time consuming of SVM Modeling : {} seconds =====\".format((time.time() - start_time)))   \n",
    "    print(results)\n",
    "    return results\n",
    "\n",
    "def modeling_ap_AdaB(k, train_data, valid_data, target = 'target_p001_10'):\n",
    "    start_time = time.time()\n",
    "    k = k\n",
    "    train_mart = train_data\n",
    "    valid_mart = valid_data\n",
    "    target = target\n",
    "    \n",
    "    X_train = train_mart.iloc[:,1:k+1]\n",
    "    y_train = train_mart[target]\n",
    "    X_valid = valid_mart.iloc[:,1:k+1]\n",
    "    y_valid = valid_mart[target]\n",
    "    \n",
    "    model = AdaBoostClassifier(n_estimators=200, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_preds = model.predict(X_valid)\n",
    "    y_probs = model.predict_proba(X_valid)\n",
    "    results = average_precision_score(y_true=y_valid.values, y_score=y_probs[:,1])\n",
    "    print(\"===== The time consuming of AdaBoosting Modeling : {} seconds =====\".format((time.time() - start_time)))   \n",
    "    print(results)\n",
    "    return results\n",
    "\n",
    "def modeling_ap_Boost(k, train_data, valid_data, target = 'target_p001_10'):\n",
    "    start_time = time.time()\n",
    "    k = k\n",
    "    train_mart = train_data\n",
    "    valid_mart = valid_data\n",
    "    target = target\n",
    "    \n",
    "    X_train = train_mart.iloc[:,1:k+1]\n",
    "    y_train = train_mart[target]\n",
    "    X_valid = valid_mart.iloc[:,1:k+1]\n",
    "    y_valid = valid_mart[target]\n",
    "    \n",
    "    model = GradientBoostingClassifier(n_estimators=200, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_preds = model.predict(X_valid)\n",
    "    y_probs = model.predict_proba(X_valid)\n",
    "    results = average_precision_score(y_true=y_valid.values, y_score=y_probs[:,1])\n",
    "    print(\"===== The time consuming of Boosting Modeling : {} seconds =====\".format((time.time() - start_time)))   \n",
    "    print(results)\n",
    "    return results\n",
    "\n",
    "def modeling_ap_xgb(k, train_data, valid_data, target = 'target_p001_10'):\n",
    "    start_time = time.time()\n",
    "    k = k\n",
    "    train_mart = train_data\n",
    "    valid_mart = valid_data\n",
    "    target = target\n",
    "    \n",
    "    X_train = train_mart.iloc[:,1:k+1]\n",
    "    y_train = train_mart[target]\n",
    "    X_valid = valid_mart.iloc[:,1:k+1]\n",
    "    y_valid = valid_mart[target]\n",
    "    \n",
    "    model = XGBClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_preds = model.predict(X_valid)\n",
    "    y_probs = model.predict_proba(X_valid)\n",
    "    results = average_precision_score(y_true=y_valid.values, y_score=y_probs[:,1])\n",
    "    print(\"===== The time consuming of XgBoosting Modeling : {} seconds =====\".format((time.time() - start_time)))   \n",
    "    print(results)\n",
    "    return results\n",
    "\n",
    "def modeling_ap_lgbm(k, train_data, valid_data, target = 'target_p001_10'):\n",
    "    start_time = time.time()\n",
    "    k = k\n",
    "    train_mart = train_data\n",
    "    valid_mart = valid_data\n",
    "    target = target\n",
    "    \n",
    "    X_train = train_mart.iloc[:,1:k+1]\n",
    "    y_train = train_mart[target]\n",
    "    X_valid = valid_mart.iloc[:,1:k+1]\n",
    "    y_valid = valid_mart[target]\n",
    "    \n",
    "    model = LGBMClassifier(n_erandom_state=0, n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_preds = model.predict(X_valid)\n",
    "    y_probs = model.predict_proba(X_valid)\n",
    "    results = average_precision_score(y_true=y_valid.values, y_score=y_probs[:,1])\n",
    "    print(\"===== The time consuming of XgBoosting Modeling : {} seconds =====\".format((time.time() - start_time)))   \n",
    "    print(results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== The time consuming of SVM Modeling : 13.5096669197 seconds =====\n",
      "0.05229870968993119\n",
      "===== The time consuming of SVM Modeling : 13.4838149548 seconds =====\n",
      "0.058798417072135276\n",
      "===== The time consuming of SVM Modeling : 13.3538599014 seconds =====\n",
      "0.4779058189539346\n"
     ]
    }
   ],
   "source": [
    "k = norm_data.shape[1]\n",
    "SVM_results_p001 = modeling_ap_SVM(k=k, train_data = train_mart, valid_data = valid_mart, target = 'target_p001_10')\n",
    "SVM_results_p002 = modeling_ap_SVM(k=k, train_data = train_mart, valid_data = valid_mart, target = 'target_p002_10')\n",
    "SVM_results_p003 = modeling_ap_SVM(k=k, train_data = train_mart, valid_data = valid_mart, target = 'target_p003_10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== The time consuming of AdaBoosting Modeling : 5.50566697121 seconds =====\n",
      "0.06038898518597128\n",
      "===== The time consuming of AdaBoosting Modeling : 5.53416013718 seconds =====\n",
      "0.08541283242440459\n",
      "===== The time consuming of AdaBoosting Modeling : 5.42733192444 seconds =====\n",
      "0.11844260385818306\n"
     ]
    }
   ],
   "source": [
    "AdaB_results_p001 = modeling_ap_AdaB(k=k, train_data = train_mart, valid_data = valid_mart, target = 'target_p001_10')\n",
    "AdaB_results_p002 = modeling_ap_AdaB(k=k, train_data = train_mart, valid_data = valid_mart, target = 'target_p002_10')\n",
    "AdaB_results_p003 = modeling_ap_AdaB(k=k, train_data = train_mart, valid_data = valid_mart, target = 'target_p003_10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== The time consuming of Boosting Modeling : 8.39383792877 seconds =====\n",
      "0.10199230216725215\n",
      "===== The time consuming of Boosting Modeling : 8.57782292366 seconds =====\n",
      "0.08413041617594157\n",
      "===== The time consuming of Boosting Modeling : 7.9631228447 seconds =====\n",
      "0.2032935070908536\n"
     ]
    }
   ],
   "source": [
    "Boost_results_p001 = modeling_ap_Boost(k=k, train_data = train_mart, valid_data = valid_mart, target = 'target_p001_10')\n",
    "Boost_results_p002 = modeling_ap_Boost(k=k, train_data = train_mart, valid_data = valid_mart, target = 'target_p002_10')\n",
    "Boost_results_p003 = modeling_ap_Boost(k=k, train_data = train_mart, valid_data = valid_mart, target = 'target_p003_10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== The time consuming of XgBoosting Modeling : 13.110724926 seconds =====\n",
      "0.07612313264975729\n",
      "===== The time consuming of XgBoosting Modeling : 13.025233984 seconds =====\n",
      "0.07148545613244141\n",
      "===== The time consuming of XgBoosting Modeling : 13.126335144 seconds =====\n",
      "0.3139753639029895\n"
     ]
    }
   ],
   "source": [
    "Xgb_results_p001 = modeling_ap_xgb(k=k, train_data = train_mart, valid_data = valid_mart, target = 'target_p001_10')\n",
    "Xgb_results_p002 = modeling_ap_xgb(k=k, train_data = train_mart, valid_data = valid_mart, target = 'target_p002_10')\n",
    "Xgb_results_p003 = modeling_ap_xgb(k=k, train_data = train_mart, valid_data = valid_mart, target = 'target_p003_10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== The time consuming of XgBoosting Modeling : 6.77059006691 seconds =====\n",
      "0.056751051826715734\n",
      "===== The time consuming of XgBoosting Modeling : 6.78629589081 seconds =====\n",
      "0.08525656893756202\n",
      "===== The time consuming of XgBoosting Modeling : 6.77073502541 seconds =====\n",
      "0.12622753023391728\n"
     ]
    }
   ],
   "source": [
    "LGBM_results_p001 = modeling_ap_lgbm(k=k, train_data = train_mart, valid_data = valid_mart, target = 'target_p001_10')\n",
    "LGBM_results_p002 = modeling_ap_lgbm(k=k, train_data = train_mart, valid_data = valid_mart, target = 'target_p002_10')\n",
    "LGBM_results_p003 = modeling_ap_lgbm(k=k, train_data = train_mart, valid_data = valid_mart, target = 'target_p003_10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===== The time consuming of SVM Modeling : 6.78026795387 seconds =====\n",
    "0.037813639154038584\n",
    "===== The time consuming of SVM Modeling : 6.6843829155 seconds =====\n",
    "0.042515897441134584\n",
    "===== The time consuming of SVM Modeling : 6.79400086403 seconds =====\n",
    "0.23016056095521928"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===== The time consuming of AdaBoosting Modeling : 2.99216413498 seconds =====\n",
    "0.07452626524617899\n",
    "===== The time consuming of AdaBoosting Modeling : 2.99656176567 seconds =====\n",
    "0.08403003528707245\n",
    "===== The time consuming of AdaBoosting Modeling : 2.99476003647 seconds =====\n",
    "0.09219943362419089"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===== The time consuming of Boosting Modeling : 4.99071788788 seconds =====\n",
    "0.08310967054057486\n",
    "===== The time consuming of Boosting Modeling : 4.99086213112 seconds =====\n",
    "0.08277607559261606\n",
    "===== The time consuming of Boosting Modeling : 4.72514605522 seconds =====\n",
    "0.2678300605904397"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===== The time consuming of XgBoosting Modeling : 6.4967110157 seconds =====\n",
    "0.09871126378293811\n",
    "===== The time consuming of XgBoosting Modeling : 6.55879688263 seconds =====\n",
    "0.06946966259440435\n",
    "===== The time consuming of XgBoosting Modeling : 6.62962818146 seconds =====\n",
    "0.308958578141431"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
